# parameters for safe control in SCARA robot environment

# env setting 
robot_kwargs:
  dt: 0.00416667  # 1 / 240
  m_1: 1.0
  l_1: 1.0
  m_2: 0.5
  l_2: 1.0

  # joint position limits
  q_limit:
    low:
      - -1.57
      - -1.57
    high:
      - 1.57
      - 1.57
  
  # joint velocity limits
  dq_limit:
    low:
      - -2.0
      - -2.0
    high:
      - 2.0
      - 2.0
  
  # joint torque limits
  u_limit:
    low:
      - -5.0
      - -5.0
    high:
      - 5.0
      - 5.0


# parameter learning setting
param_learning_kwargs:
  use_online_adaptation: false
  m_2_mean_init: 1.0
  m_2_std_init: 0.3


# safe control setting
safe_control_kwargs:
  param_dict:
    alpha: 0.57
    k_v: 2.15
    beta: 0.072

  rssa_types: # just four types: 'none', 'safety_index', 'gaussian_rssa', 'convex_rssa'
    - 'safety_index'
    - 'gaussian_rssa'
    - 'convex_rssa'
    # - 'none'

  use_true_param: false # 'safety_index'
  sample_points_num: 20 # 'gaussian_rssa', 'convex_rssa'
  gamma: 0.1
  confidence_level: 0.05 # 'gaussian_rssa'
  rho: 18.59 # 'safety index', for baseline
  fast_SegWay: false


# task setting
track_kwargs: # in SCARA, we implement a tracking task
  q_start:
    - 1.5
    - -0.01
  q_end:
    - -1.0
    - -3.1
  dq_start:
    - -0.01
    - -0.01
  waypoint_num: 400
  control_repeat_times: 3 # for each waypoint, how many times we set our control input to the robot
  

# CBF learning setting
CBF_learning_kwargs:
  rssa_type: 'gaussian_rssa'
  epoch: 10
  elite_ratio: 0.1
  populate_num: 100
  init_sigma_ratio: 0.3
  noise_ratio: 0.01
  states_sampled_per_param: 1000
  iteration_limit: 3000
  reward_clip_ratio: 0.1

  param_bounds: 
    alpha: 
      - 0.1
      - 5.0
    k_v: 
      - 0.1
      - 5.0
    beta: 
      - 0.001
      - 1.0

  # for visualization
  visualize_set: 'L_and_V' # three choices: 'only_V', 'only_L', 'L_and_V'
  q_sampled_per_dim: 20
  dq_num: 50


# FI sets setting
FI_sets_kwargs:
  offset: 0.0
  if_binary: true